---
title: "p8105_hw2_bes2161"
author: "Brittany Shea"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r load_libraries}
library(tidyverse)
library(readxl)
library(lubridate)
```

### Problem 1

```{r}
trans_ent = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

The dataset shows NYC Transit data with information on entrances and exits for subway stations. These data are not tidy because route and route # should be variables. We should convert `route` variables from wide to long format. So far we have imported data, updated variable names, and selected the columns to use. We updated `entry` from `yes` / `no` to a logical variable. We specify that `Route` columns 8-11 should be character. There are 20 columns and 1868 rows.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```
There are 465 unique stations.

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```
There are 84 ADA compliant stations. 

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```
The proportion of station entrances / exits without vending that allow entrance is 0.377.

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```
60 stations serve the A train, and 17 are ADA compliant.

### Problem 2

# Mr. Trash Wheel
```{r}
mr_trash_wheel = 
  read_xlsx("data/Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel")  %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  select(dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, glass_bottles, grocery_bags, chip_bags, sports_balls, homes_powered) %>% 
  rename(dumpster_number = dumpster, weight = weight_tons, cigarettes = cigarette_butts, volume = volume_cubic_yards) %>% 
  mutate(sports_balls = as.integer(sports_balls), name = "mr")
```

# Prof. Trash Wheel
```{r}
prof_trash_wheel =
  read_xlsx("data/Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel")  %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  select(dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, glass_bottles, grocery_bags, chip_bags, homes_powered) %>% 
  rename(dumpster_number = dumpster, weight = weight_tons, cigarettes = cigarette_butts, volume = volume_cubic_yards) %>% 
  mutate(name = "prof", year = as.character(year))
```

# Both Trash Wheels
```{r}
all_trash = 
  full_join(mr_trash_wheel, prof_trash_wheel) %>%
  relocate(name, dumpster_number) 
```

There are 641 observations and 15 variables in the final dataset. Some of the key variables are the types of trash, such as glass bottles and grocery bags, and homes powered. The total weight of trash collected by Professor Trash Wheel was `r sum(pull(filter(prof_trash_wheel), weight))`. The total number of sports balls collected by Mr. Trash Wheel in 2020 was `r sum(pull(filter(mr_trash_wheel, year == 2020), sports_balls))`.

### Problem 3

# National politicians:
```{r}
pols_month =
  read_csv("data/fivethirtyeight_datasets/pols-month.csv")  %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day")) %>%
  mutate(month = month.abb[as.numeric(month)]) %>%
  mutate(president = recode(prez_gop, "0" = "dem", "1" = "gop")) %>%
  select(-prez_dem, -prez_gop, -day) %>%
  mutate(month = tolower(month)) %>%
  mutate(year = as.numeric(year))
```

# Standard & Poor's stock market index (S&P):
```{r}
snp =
  read_csv("data/fivethirtyeight_datasets/snp.csv")  %>%
  janitor::clean_names() %>%
  mutate(date = parse_date_time2(date,'mdy',cutoff_2000 = 49)) %>%
  separate(date, into = c("year", "month", "day")) %>%
  mutate(month = month.abb[as.numeric(month)]) %>%
  relocate(year, month) %>%
  mutate(month = tolower(month)) %>%
  mutate(year = as.numeric(year))
```

# Unemployment:
```{r}
unemployment =
  read_csv("data/fivethirtyeight_datasets/unemployment.csv")  %>%
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to = "month", 
    values_to = "unemployment") %>%
  mutate(year = as.numeric(year))
```

# Join datasets
```{r}
join1 = 
  left_join(pols_month, snp, by = c("year", "month"))

join2 = 
  left_join(join1, unemployment, by = c("year", "month"))
```

These datasets include information on the number of national politicians who are democratic or republican, unemployment, and data on the Standard & Poorâ€™s stock market. I combined the datasets and organized based on year and month. The final dataset has 822 observations and 12 variables from `r range(pull(join2,year))`. Some key variables include the political status of presidents, the closing values of the S&P stock index by date, and  percentage of unemployment in the month of the listed year.